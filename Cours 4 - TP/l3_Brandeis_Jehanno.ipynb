{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab session is to code an optimization algorithm that optimzes the penalized loss function of the logistic regression model.\n",
    "\n",
    "You have to send the filled notebook named **\"L3_familyname1_familyname2.ipynb\"** (groups of 2) by email to aml.centralesupelec.2019@gmail.com by October 17, 2019. Please put **\"AML-L3\"** in the subject. \n",
    "\n",
    "We begin with the standard imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the dataset that we are going to use, an indian dataset including in the last column information about the diabetes status of patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "diabetes_data = pd.read_csv(\"diabetes_data.csv\", sep=\",\")\n",
    "\n",
    "diabetes_train, diabetes_test = model_selection.train_test_split(diabetes_data)\n",
    "diabetes_train_x = diabetes_train.iloc[:, :-1].values\n",
    "diabetes_train_y = diabetes_train.iloc[:, -1].values\n",
    "diabetes_train_y[diabetes_train_y == 0] = -1\n",
    "\n",
    "diabetes_test_x = diabetes_test.iloc[:, :-1].values\n",
    "diabetes_test_y = diabetes_test.iloc[:, -1].values\n",
    "diabetes_test_y[diabetes_test_y == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today weâ€™ll be moving from linear regression to logistic regression, one of the simplest ways to deal with a classification problem. Instead of fitting a line, logistic regression models the probability that the outcome is 1 given the value of the predictor. In order to do this we need a function that transforms our predictor variable to a value between 0 and 1. Lots of functions can do that, but the logistic function is the most common choice:\n",
    "\n",
    "$$f(z) = \\frac{1}{1+\\exp{-z}}.$$\n",
    "\n",
    "To predict the class of our observations we'll have to minimize the corresponding loss function and as we are in a high-dimensional context we'll add an $l_2$ regularization to the model:\n",
    "\n",
    "$$F(\\textbf{w}) = \\sum_{i=1}^n log(1+\\exp(-y_i\\textbf{w}^Tx_i))+\\frac{\\lambda}{2} \\| \\textbf{w} \\|^2,$$\n",
    "\n",
    "where $x_i$ is the vector of features for the observation $i$ and $y_i \\in \\{-1, 1\\}$ is the class label.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use the `sklearn` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty=\"l2\", C=2) \n",
    "model.fit(diabetes_train_x, diabetes_train_y)\n",
    "y_pred = model.predict(diabetes_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we compute the accuracy score to evaluate the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8385416666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(diabetes_test_y,return_counts=True)from sklearn.metrics import accuracy_score\n",
    "accuracy_score(diabetes_test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the classes balance is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1 is represented by 69.8% of the data.\n",
      "Class 1 is represented by 30.2% of the data.\n"
     ]
    }
   ],
   "source": [
    "stats = np.unique(diabetes_test_y,return_counts=True)\n",
    "for index in range(len(stats[0])):\n",
    "    print(\"Class {0} is represented by {1:.1f}% of the data.\".format(stats[0][index],\n",
    "                                                                     stats[1][index]*100/np.sum(stats[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "Implement from scratch your own logistic regression model with stochastic gradient descent optimization. \n",
    "\n",
    "- Fill in the class\n",
    "\n",
    "- Display the evolution of the cost function along iterations. Do this for several strategies for the setting of the learning rate\n",
    "\n",
    "- Try the different acceleration strategies\n",
    "\n",
    "- Train the model with the training set and evaluate its performance in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of F is :\n",
    "\n",
    "$$\\nabla F(\\textbf{w}) = \\sum_{i=1}^n \\frac{-y_i*\\textbf{x}_i}{1+\\exp(y_i\\textbf{w}^T\\textbf{x}_i)}+\\lambda*\\textbf{w},$$\n",
    "\n",
    "Where $\\lambda$ is the regularization of the model : it prevents the model from overfitting the data by imposing low values of the model's coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write F using a decomposition $$F(\\textbf{w})=\\sum_{i=1}^n f_i(\\textbf{w})$$ with $$f_i(\\textbf{w})=log(1+\\exp(-y_i\\textbf{w}^Tx_i))+\\frac{\\lambda}{2*n} \\| \\textbf{w} \\|^2,$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticLogisticRegression():\n",
    "    \"\"\" Class for logistic regression:\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    coef_: 1-dimensional np.array\n",
    "        coefficients \n",
    "    alpha_: float\n",
    "        regularization parameter\n",
    "    lr_: float\n",
    "        the learning rate\n",
    "    bsize: integer\n",
    "        the size of the mini-batch >=1\n",
    "    coef_history_: list\n",
    "        the list of all visited betas\n",
    "    f_history_: list \n",
    "        the list of all evaluations in visited betas\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha, lr=1e-1, batch_size=50, max_iter=500):\n",
    "        self.coef_  = None\n",
    "        self.alpha_ = alpha\n",
    "        self.lr_ = lr\n",
    "        self.batch_size_ = batch_size\n",
    "        self.max_iter_ = max_iter\n",
    "        self.coef_history_ = []\n",
    "        self.f_history_ = []\n",
    "\n",
    "    def logistic(self, z):\n",
    "        # logistic function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def set_lr(self, itr, C=2):\n",
    "        self.lr_ = C / itr\n",
    "        \n",
    "    def evolving_lr(self, init, final, max_itr, itr):\n",
    "        \"\"\"\n",
    "        Returns the learning rate to use at the iteration itr.\n",
    "\n",
    "        The idea is to use a learning rate decreasing according to an inverse sigmoid function.\n",
    "\n",
    "        Params:\n",
    "            init : initial value of the learning rate\n",
    "            final : final value of the learning rate\n",
    "            max_itr : the number of iterations used in the process\n",
    "            itr : the iteration number at which we are\n",
    "        \"\"\"\n",
    "        alpha = 2 * (np.log((init-final)/final) - np.log(np.sqrt(init/final)-1)) / max_itr\n",
    "        beta = np.log((init + final - 2*np.sqrt(init*final))/(init - final))\n",
    "        return init / (1 + np.exp(alpha*itr+beta))\n",
    "    \n",
    "        \n",
    "    def fit(self, X, y, start):\n",
    "        \"\"\" Fit the data (X, y).\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        y: (num_sampes, ) np.array\n",
    "            Output vector\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        Updates self.coef_\n",
    "        \"\"\"\n",
    "        \n",
    "        # Let's normalize X\n",
    "        X = (X - np.mean(X)) / (np.std(X)+1e-3)\n",
    "        \n",
    "        # Let's add the intercept\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:, 1:] = X\n",
    "        X = X_aug\n",
    "        \n",
    "        def f_lr(beta):\n",
    "            '''evaluate the F=\\sum_{i=1}^n f_i in beta'''\n",
    "            F = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                F += np.log(1 + np.exp(-y[i]*np.matmul(np.transpose(X[i]), beta)))\n",
    "            \n",
    "            return F + self.alpha_*0.5*np.matmul(np.transpose(beta), beta)\n",
    "        \n",
    "        def grad_logistic_loss(beta, batch):\n",
    "            grad = 0\n",
    "            for sample_idx in batch:\n",
    "                y_i = y[sample_idx]\n",
    "                x_i = X[sample_idx]\n",
    "                grad += - y_i * x_i / (1 + np.exp(y_i*np.matmul(x_i, beta))) + self.alpha_*beta / X.shape[0]\n",
    "            return grad\n",
    "        \n",
    "        \n",
    "        self.coef_ = start\n",
    "        self.coef_history_.append(self.coef_)\n",
    "        self.f_history_.append(f_lr(self.coef_))\n",
    "        \n",
    "        # Batches creation\n",
    "        batches = []\n",
    "        indexes = list(range(X.shape[0]))\n",
    "        while len(indexes) > 0:\n",
    "            batch = []\n",
    "            while len(batch) < self.batch_size_ and len(indexes) > 0:\n",
    "                i = np.random.randint(low=0,high=len(indexes),size=1)[0]\n",
    "                batch.append(indexes.pop(i))\n",
    "            batches.append(batch)\n",
    "            \n",
    "            \n",
    "        itr = 0\n",
    "        while itr < self.max_iter_: # critere de convergence\n",
    "            self.lr_ = self.evolving_lr(1e-1, 1e-5, self.max_iter_, itr)\n",
    "            itr += 1\n",
    "            #self.set_lr(itr)\n",
    "            self.coef_ = self.coef_ - self.lr_ * grad_logistic_loss(self.coef_, batch=batches[itr%len(batches)])\n",
    "\n",
    "            # Update the memory\n",
    "            self.coef_history_.append(self.coef_)\n",
    "            self.f_history_.append(f_lr(self.coef_))\n",
    "            \n",
    "         \n",
    "    def predict(self, X):\n",
    "        \"\"\" Make binary predictions for data X.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        \n",
    "        Returns:\n",
    "        -----\n",
    "        y_pred: (num_samples, ) np.array\n",
    "            Predictions (0 or 1)\n",
    "        \"\"\"\n",
    "        X = (X - np.mean(X)) / (np.std(X)+1e-3)\n",
    "        \n",
    "        # Let's add the intercept\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:, 1:] = X\n",
    "        X = X_aug\n",
    "        \n",
    "        y_pred = self.logistic(np.matmul(X,self.coef_)) > 0.5\n",
    "        y_pred = y_pred.astype(int) # y_pred = 0 or 1 according to the probability\n",
    "        y_pred = y_pred*2 - 1 # the classes are -1 or 1\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** : The maximum value for the stepsize $\\theta$ is $$(\\frac{1}{4}*\\sum_{i=1}^n \\| \\textbf{x}_i \\|^2+\\lambda)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value of the stepsize for alpha=10 the stepsize is : 0.0008620982435086248\n",
      "The maximum value of the stepsize for alpha=1 the stepsize is : 0.0008688394683244258\n",
      "The maximum value of the stepsize for alpha=0.1 the stepsize is : 0.0008695193938154643\n",
      "The maximum value of the stepsize for alpha=0.01 the stepsize is : 0.0008695874448987805\n",
      "The maximum value of the stepsize for alpha=0.001 the stepsize is : 0.0008695942505929627\n"
     ]
    }
   ],
   "source": [
    "def stepsize_max(alpha):\n",
    "    stepsize_max = 0\n",
    "    X = (diabetes_train_x - np.mean(diabetes_train_x)) / (np.std(diabetes_train_x)+1e-3)\n",
    "    for index in range(len(diabetes_train_x)):\n",
    "        stepsize_max += np.matmul(np.transpose(X[index]),X[index])\n",
    "    stepsize_max = 1/(stepsize_max/4 + alpha)\n",
    "    \n",
    "    return stepsize_max\n",
    "\n",
    "for alpha in [10, 1, 1e-1, 1e-2, 1e-3]:\n",
    "    print(\"The maximum value of the stepsize for alpha={0} the stepsize is : {1}\".format(alpha,stepsize_max(alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = StochasticLogisticRegression(alpha=.001, lr=5e-4, batch_size=100, max_iter=5000) \n",
    "my_model.fit(diabetes_train_x, diabetes_train_y, start=np.random.rand(diabetes_train_x.shape[1]+1))\n",
    "y_pred = my_model.predict(diabetes_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we compute the accuracy score to evaluate the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177083333333334"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(diabetes_test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the evolution of our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[502.5210727841812,\n",
       " inf,\n",
       " inf,\n",
       " 21587.65765251899,\n",
       " 7514.362994332021,\n",
       " 2093.3038835941493,\n",
       " 7791.652712747741,\n",
       " 5667.764279738553,\n",
       " 2203.982458936577,\n",
       " 1744.9362593184867,\n",
       " 2571.7909250057446,\n",
       " 1313.3644137428194,\n",
       " 1407.211550819625,\n",
       " 1139.295415082016,\n",
       " 1118.1400795881152,\n",
       " 1056.7227225833233,\n",
       " 1016.641997369787,\n",
       " 1005.9259048611191,\n",
       " 1042.096714437143,\n",
       " 956.7787030211839,\n",
       " 978.4112788110918,\n",
       " 927.5790665517645,\n",
       " 919.0720347013859,\n",
       " 905.7058759751981,\n",
       " 924.5992983963636,\n",
       " 881.3759544889069,\n",
       " 902.3343418425088,\n",
       " 850.1524505123324,\n",
       " 842.3976219832749,\n",
       " 834.2384852368086,\n",
       " 841.445203950448,\n",
       " 823.7742749484953,\n",
       " 826.3909733113979,\n",
       " 789.5954507863686,\n",
       " 782.2449479998222,\n",
       " 776.6681838221049,\n",
       " 779.3759130784599,\n",
       " 771.1534318582286,\n",
       " 766.6342100767578,\n",
       " 740.1447227333628,\n",
       " 733.2734063002512,\n",
       " 729.1870301872331,\n",
       " 729.6399082330402,\n",
       " 725.8450633131744,\n",
       " 718.5713895264929,\n",
       " 698.4752616961022,\n",
       " 692.3016405208512,\n",
       " 689.0613281912036,\n",
       " 688.3128788538537,\n",
       " 686.944102490001,\n",
       " 678.5869669887213,\n",
       " 662.6952861850204,\n",
       " 657.2701046641776,\n",
       " 654.5486909516293,\n",
       " 653.1298542770204,\n",
       " 653.2108064281566,\n",
       " 644.5115130201707,\n",
       " 631.5442218567946,\n",
       " 626.8290020795337,\n",
       " 624.4535809875887,\n",
       " 622.6559193432564,\n",
       " 623.6303617586085,\n",
       " 614.9653381655693,\n",
       " 604.1260096537443,\n",
       " 600.0471124891268,\n",
       " 597.9207057852576,\n",
       " 595.9166181734001,\n",
       " 597.4371344606392,\n",
       " 589.0123214276756,\n",
       " 579.7785305432623,\n",
       " 576.2536593428946,\n",
       " 574.3188108014986,\n",
       " 572.2157964987907,\n",
       " 574.0556271124967,\n",
       " 565.9845401034823,\n",
       " 557.9986259220391,\n",
       " 554.9488944104124,\n",
       " 553.1698068345162,\n",
       " 551.037032293463,\n",
       " 553.0459853532368,\n",
       " 545.387001098865,\n",
       " 538.3953852787104,\n",
       " 535.7502390614527,\n",
       " 534.1034656126255,\n",
       " 531.9859876184227,\n",
       " 534.0648395871594,\n",
       " 526.8419454654073,\n",
       " 520.6594833059357,\n",
       " 518.3580926317946,\n",
       " 516.827449215044,\n",
       " 514.7545063666286,\n",
       " 516.8386250384281,\n",
       " 510.0542119310458,\n",
       " 504.5422619638633,\n",
       " 502.533231133704,\n",
       " 501.1069207665318,\n",
       " 499.09711222253094,\n",
       " 501.14544191463006,\n",
       " 494.78860948262246,\n",
       " 489.84102505204794,\n",
       " 488.0813843307061,\n",
       " 486.7503327743602,\n",
       " 484.8150115103705,\n",
       " 486.8025120692931,\n",
       " 480.85455250184157,\n",
       " 476.38844942548815,\n",
       " 474.84242922259006,\n",
       " 473.5993037941621,\n",
       " 471.7448658189574,\n",
       " 473.65729453455987,\n",
       " 468.0953037090668,\n",
       " 464.04481087946766,\n",
       " 462.6826422876573,\n",
       " 461.5212638796852,\n",
       " 459.7507174529152,\n",
       " 461.5810318217279,\n",
       " 456.3802552324757,\n",
       " 452.69218399901195,\n",
       " 451.48903051736585,\n",
       " 450.40401541772115,\n",
       " 448.7180651615145,\n",
       " 450.46395157411973,\n",
       " 445.5992756908728,\n",
       " 442.230055256357,\n",
       " 441.1651077082536,\n",
       " 440.1516454959929,\n",
       " 438.54944382213415,\n",
       " 440.21162697820824,\n",
       " 435.65849806119695,\n",
       " 432.5719652800066,\n",
       " 431.6276966024542,\n",
       " 430.68140963239256,\n",
       " 429.16107805425156,\n",
       " 430.74217004396644,\n",
       " 426.47713363480113,\n",
       " 423.6429114128226,\n",
       " 422.8044730626072,\n",
       " 421.9213254905698,\n",
       " 420.48031621060136,\n",
       " 421.98403760714035,\n",
       " 417.98502993713083,\n",
       " 415.37731890320583,\n",
       " 414.63205621362704,\n",
       " 413.80829350532576,\n",
       " 412.4436400407864,\n",
       " 413.8742969348937,\n",
       " 410.1207765308039,\n",
       " 407.7174420368964,\n",
       " 407.05450645528316,\n",
       " 406.28661392487817,\n",
       " 404.99510467661804,\n",
       " 406.3572415658239,\n",
       " 402.83021989428136,\n",
       " 400.61209352869076,\n",
       " 400.02213232616384,\n",
       " 399.3068057460145,\n",
       " 398.0851041004443,\n",
       " 399.38327746795824,\n",
       " 396.06528751122227,\n",
       " 394.015626768351,\n",
       " 393.49053405209844,\n",
       " 392.8246580592785,\n",
       " 391.6693854209196,\n",
       " 392.9080200159518,\n",
       " 389.78304827920334,\n",
       " 387.8871144218479,\n",
       " 387.4198304021229,\n",
       " 386.8004620447518,\n",
       " 385.70825517484934,\n",
       " 386.89155681266243,\n",
       " 383.94495533709915,\n",
       " 382.18968065648556,\n",
       " 381.7740288465898,\n",
       " 381.19838459640044,\n",
       " 380.1659351282792,\n",
       " 381.29784193782484,\n",
       " 378.5162309781909,\n",
       " 376.8899543911825,\n",
       " 376.52050867540095,\n",
       " 375.98595383597024,\n",
       " 375.01003539598133,\n",
       " 376.09419501810976,\n",
       " 373.46536314004595,\n",
       " 371.95761850408866,\n",
       " 371.62959381737267,\n",
       " 371.1336336304345,\n",
       " 370.2111202967706,\n",
       " 371.25088437683337,\n",
       " 368.76369016365385,\n",
       " 367.3650355779128,\n",
       " 367.0741973607537,\n",
       " 366.61446934600946,\n",
       " 365.74234800368055,\n",
       " 366.74077797613313,\n",
       " 364.38505585430124,\n",
       " 363.0869350359192,\n",
       " 362.8295237262987,\n",
       " 362.4037909374343,\n",
       " 361.57916927960645,\n",
       " 362.5390492823231,\n",
       " 360.30552087907046,\n",
       " 359.10014977967415,\n",
       " 358.87281744569367,\n",
       " 358.47896241995255,\n",
       " 357.6990737933838,\n",
       " 358.6229278301236,\n",
       " 356.5031195662757,\n",
       " 355.38339294324595,\n",
       " 355.18314980103884,\n",
       " 354.8191690417861,\n",
       " 354.0813749593915,\n",
       " 354.97148632376127,\n",
       " 352.95765348832043,\n",
       " 351.9170673163332,\n",
       " 351.7412363644078,\n",
       " 351.4052352380652,\n",
       " 350.7070261297322,\n",
       " 351.5654577316306,\n",
       " 349.65051499552965,\n",
       " 348.6831014988767,\n",
       " 348.52927986917,\n",
       " 348.2194678271928,\n",
       " 347.55846243221896,\n",
       " 348.38707710935216,\n",
       " 346.56453525695287,\n",
       " 345.6648080338528,\n",
       " 345.53083394054215,\n",
       " 345.2455199984068,\n",
       " 344.6194636920502,\n",
       " 345.41994390066685,\n",
       " 343.68385245158754,\n",
       " 342.84675969897035,\n",
       " 342.730684080832,\n",
       " 342.4682725020731,\n",
       " 341.8750347758211,\n",
       " 342.6489012748561,\n",
       " 340.99379661075767,\n",
       " 340.21468087858085,\n",
       " 340.11474299628856,\n",
       " 339.87372914216263,\n",
       " 339.3113004092542,\n",
       " 340.05992970748935,\n",
       " 338.4807882921483,\n",
       " 337.75535152697574,\n",
       " 337.6699579059283,\n",
       " 337.4489242213405,\n",
       " 336.9154120869403,\n",
       " 337.6400525321843,\n",
       " 336.1322488076834,\n",
       " 335.4565217060019,\n",
       " 335.38422791739697,\n",
       " 335.18184003185036,\n",
       " 334.6754651450732,\n",
       " 335.3772516109098,\n",
       " 333.93652016071337,\n",
       " 333.30683505840136,\n",
       " 333.24632991320175,\n",
       " 333.0613328421749,\n",
       " 332.5804244309709,\n",
       " 333.2603916095529,\n",
       " 331.8827931957413,\n",
       " 331.2957598827476,\n",
       " 331.24585167989875,\n",
       " 331.07706611741537,\n",
       " 330.62005729469666,\n",
       " 331.2791516399299,\n",
       " 329.9610427435718,\n",
       " 329.41352672122343,\n",
       " 329.37313124655066,\n",
       " 329.21944994397927,\n",
       " 328.78487286277453,\n",
       " 329.4239632517501,\n",
       " 328.161968770031,\n",
       " 327.6510715694843,\n",
       " 327.619201587741,\n",
       " 327.47958581717285,\n",
       " 327.06606674314827,\n",
       " 327.68595393825524,\n",
       " 326.47694271794967,\n",
       " 325.9999839777406,\n",
       " 325.97573999911697,\n",
       " 325.8492161021379,\n",
       " 325.45547046313015,\n",
       " 326.0568954653262,\n",
       " 324.8979583784471,\n",
       " 324.4524594412993,\n",
       " 324.4350215767105,\n",
       " 324.32067760112847,\n",
       " 323.94550506510774,\n",
       " 324.5291564521965,\n",
       " 323.41758674543775,\n",
       " 323.0012555830169,\n",
       " 322.98987633067554,\n",
       " 322.8868587588774,\n",
       " 322.52913838400934,\n",
       " 323.0956587277773,\n",
       " 322.0289344021766,\n",
       " 321.6396517142183,\n",
       " 321.6336495440805,\n",
       " 321.5411601172856,\n",
       " 321.19984561047187,\n",
       " 321.7498370641672,\n",
       " 320.725605064928,\n",
       " 320.3614114283623,\n",
       " 320.36016505168385,\n",
       " 320.2774576945055,\n",
       " 319.9515728079979,\n",
       " 320.4856019516411,\n",
       " 319.5016639700987,\n",
       " 319.16074793632816,\n",
       " 319.1636911651505,\n",
       " 319.0900690147245,\n",
       " 318.77870310418194,\n",
       " 319.297305130128,\n",
       " 318.35160484028967,\n",
       " 318.0322918960967,\n",
       " 318.0389090124994,\n",
       " 317.97372155597805,\n",
       " 317.6760253177145,\n",
       " 318.1797076331669,\n",
       " 317.2703192040789,\n",
       " 316.97106152490505,\n",
       " 316.98088309260856,\n",
       " 316.92352341621125,\n",
       " 316.63870481636087,\n",
       " 317.12795013348443,\n",
       " 316.2530678758707,\n",
       " 315.9724348104201,\n",
       " 315.9850338720653,\n",
       " 315.9349360241396,\n",
       " 315.66225642806984,\n",
       " 316.1375254061807,\n",
       " 315.2954544274494,\n",
       " 315.0321236603544,\n",
       " 315.0471122728672,\n",
       " 315.0037487426072,\n",
       " 314.7425192491218,\n",
       " 315.20425274734544,\n",
       " 314.3934005031738,\n",
       " 314.1461498485112,\n",
       " 314.1631759165382,\n",
       " 314.1260552291868,\n",
       " 313.87563321083263,\n",
       " 314.3242542037341,\n",
       " 313.5431228471671,\n",
       " 313.31082263028327,\n",
       " 313.32956700402315,\n",
       " 313.2982314325637,\n",
       " 313.058017280697,\n",
       " 313.4939324837487,\n",
       " 312.7411119241329,\n",
       " 312.52271791295203,\n",
       " 312.5428917219517,\n",
       " 312.516915114548,\n",
       " 312.2863491855906,\n",
       " 312.70995043210786,\n",
       " 311.98411202635924,\n",
       " 311.7786588763087,\n",
       " 311.8000010751382,\n",
       " 311.7789867968578,\n",
       " 311.5575465544714,\n",
       " 311.96921196070537,\n",
       " 311.26910276846326,\n",
       " 311.0756979476122,\n",
       " 311.09797305291755,\n",
       " 311.08155203963577,\n",
       " 310.86874938616876,\n",
       " 311.26884433678174,\n",
       " 310.593281879024,\n",
       " 310.41110004209656,\n",
       " 310.43409604345544,\n",
       " 310.421924965309,\n",
       " 310.21730375486266,\n",
       " 310.606181736877,\n",
       " 309.95404920469434,\n",
       " 309.78232698644194,\n",
       " 309.80585341586783,\n",
       " 309.7976129471284,\n",
       " 309.60074667189485,\n",
       " 309.97874998151167,\n",
       " 309.3489918480019,\n",
       " 309.18702304804015,\n",
       " 309.2109091949373,\n",
       " 309.20630238680775,\n",
       " 309.0167920278611,\n",
       " 309.38425237119833,\n",
       " 308.77587036498034,\n",
       " 308.6230014977053,\n",
       " 308.64709475770286,\n",
       " 308.64584551024177,\n",
       " 308.4633175437071,\n",
       " 308.8205565495408,\n",
       " 308.2326059532589,\n",
       " 308.08823213785223,\n",
       " 308.11239648526464,\n",
       " 308.1142481143852,\n",
       " 307.9383526638642,\n",
       " 308.28568232380235,\n",
       " 307.71726856525834,\n",
       " 307.5808297321503,\n",
       " 307.6049443069008,\n",
       " 307.60965820227125,\n",
       " 307.44006732841234,\n",
       " 307.7777903776295,\n",
       " 307.22806588494285,\n",
       " 307.0990432763912,\n",
       " 307.12300107713577,\n",
       " 307.13035544666957,\n",
       " 306.9667615650034,\n",
       " 307.2951718145987,\n",
       " 306.7633331100755,\n",
       " 306.6412460537733,\n",
       " 306.6649527297157,\n",
       " 306.67474142633296,\n",
       " 306.51685584470084,\n",
       " 306.83623847498853,\n",
       " 306.32152348526756,\n",
       " 306.20592642111006,\n",
       " 306.22929915563867,\n",
       " 306.24133058195764,\n",
       " 306.0888821492082,\n",
       " 306.3995139716884,\n",
       " 305.9011995342684,\n",
       " 305.79167927559257,\n",
       " 305.8146457553888,\n",
       " 305.82874184207225,\n",
       " 305.681475700063,\n",
       " 305.9836253945069,\n",
       " 305.5010249429454,\n",
       " 305.39719815471256,\n",
       " 305.4196956184758,\n",
       " 305.4356908720129,\n",
       " 305.2933673033477,\n",
       " 305.58729563528095,\n",
       " 305.119757047326,\n",
       " 305.02126792480226,\n",
       " 305.04324228611654,\n",
       " 305.06098290195627,\n",
       " 304.923376266301,\n",
       " 305.20933628920267,\n",
       " 304.7562398837865,\n",
       " 304.66275801637704,\n",
       " 304.6841630556231,\n",
       " 304.7035060926686,\n",
       " 304.57040384492916,\n",
       " 304.8486410906228,\n",
       " 304.40939776116187,\n",
       " 304.32061616705397,\n",
       " 304.34141278758767,\n",
       " 304.36222540024164,\n",
       " 304.2334271842773,\n",
       " 304.50417984432016,\n",
       " 304.0782293170492,\n",
       " 303.99386263531864,\n",
       " 304.01401817944316,\n",
       " 304.03617690351956,\n",
       " 303.9114937155208,\n",
       " 304.1749928157764,\n",
       " 303.76180202301265,\n",
       " 303.6815848507824,\n",
       " 303.7010724712982,\n",
       " 303.7244625603015,\n",
       " 303.60371597634105,\n",
       " 303.860185546462,\n",
       " 303.45924710569705,\n",
       " 303.3829324688186,\n",
       " 303.4017305522116,\n",
       " 303.42624536064176,\n",
       " 303.3092668233089,\n",
       " 303.5589240624388,\n",
       " 303.1697548530407,\n",
       " 303.0971127996203,\n",
       " 303.11520443717325,\n",
       " 303.14074484770276,\n",
       " 303.02737500709907,\n",
       " 303.27043044676896,\n",
       " 302.89257027687853,\n",
       " 302.8233865837666,\n",
       " 302.84075908710724,\n",
       " 302.86723297862784,\n",
       " 302.7573210833724,\n",
       " 302.9939787483019,\n",
       " 302.626989105184,\n",
       " 302.5610640882825,\n",
       " 302.5777085460987,\n",
       " 302.60503029982476,\n",
       " 302.49843363403716,\n",
       " 302.72889120132623,\n",
       " 302.37235407907093,\n",
       " 302.30950149902804,\n",
       " 302.3254123718859,\n",
       " 302.35350241285863,\n",
       " 302.250085775409,\n",
       " 302.4745347324376,\n",
       " 302.1280515314363,\n",
       " 302.0680975869481,\n",
       " 302.08327233732825,\n",
       " 302.1120567088353,\n",
       " 302.0116919314467,\n",
       " 302.2303177326553,\n",
       " 301.89350822577313,\n",
       " 301.8362906273271,\n",
       " 301.85072938220094,\n",
       " 301.8801393507666,\n",
       " 301.7827048518374,\n",
       " 301.9956870744577,\n",
       " 301.668188435265,\n",
       " 301.61355555271916,\n",
       " 301.6272607961443,\n",
       " 301.6572324849154,\n",
       " 301.56261285616944,\n",
       " 301.7701253548946,\n",
       " 301.45159124368337,\n",
       " 301.3994013216315,\n",
       " 301.4123776150092,\n",
       " 301.4428516635033,\n",
       " 301.3509372868267,\n",
       " 301.5531483473442,\n",
       " 301.2432480510383,\n",
       " 301.19336848636834,\n",
       " 301.2056222141935,\n",
       " 301.2365434624888,\n",
       " 301.14723015452415,\n",
       " 301.3443026458061,\n",
       " 301.0427202681559,\n",
       " 300.99502694469254,\n",
       " 301.0065660837337,\n",
       " 301.0378832793514,\n",
       " 300.9510719616228,\n",
       " 301.1431634868146,\n",
       " 300.84959718557633,\n",
       " 300.8039738611014,\n",
       " 300.8148077711302,\n",
       " 300.8464732969445,\n",
       " 300.7620696894781,\n",
       " 300.94933273523736,\n",
       " 300.6634940032644,\n",
       " 300.61983174460755,\n",
       " 300.629970978905,\n",
       " 300.66194060055454,\n",
       " 300.5798549371217,\n",
       " 300.762437021232,\n",
       " 300.48405000866313,\n",
       " 300.4422466709054,\n",
       " 300.45170280491305,\n",
       " 300.4839354362866,\n",
       " 300.40408219956373,\n",
       " 300.5821260166491,\n",
       " 300.31092689157174,\n",
       " 300.2708866377391,\n",
       " 300.2796721143399,\n",
       " 300.3121295998166,\n",
       " 300.234427274887,\n",
       " 300.4080708400677,\n",
       " 300.14380718522756,\n",
       " 300.10544004314943,\n",
       " 300.11356803317125,\n",
       " 300.14621494538744,\n",
       " 300.07058579015825,\n",
       " 300.239962580475,\n",
       " 299.9823928237879,\n",
       " 299.9456142770804,\n",
       " 299.95309855372653,\n",
       " 299.9859020057311,\n",
       " 299.9122718369463,\n",
       " 300.07751093041804,\n",
       " 299.82640380717936,\n",
       " 299.7911344175631,\n",
       " 299.7979892435734,\n",
       " 299.8309187143176,\n",
       " 299.75921670796066,\n",
       " 299.9204429201279,\n",
       " 299.6755769649872,\n",
       " 299.6417420233823,\n",
       " 299.64798204981366,\n",
       " 299.68100922199926,\n",
       " 299.6111677269864,\n",
       " 299.7685017448254,\n",
       " 299.52966481170034,\n",
       " 299.4971940157661,\n",
       " 299.5028341913774,\n",
       " 299.53593280075785,\n",
       " 299.4678871649094,\n",
       " 299.62144567800607,\n",
       " 299.38843448624993,\n",
       " 299.3572616422239,\n",
       " 299.3623171325194,\n",
       " 299.39546282781896,\n",
       " 299.3291512351787,\n",
       " 299.4790470640715,\n",
       " 299.2516667693236,\n",
       " 299.2217295161925,\n",
       " 299.2262156312725,\n",
       " 299.25938584393907,\n",
       " 299.19474916259827,\n",
       " 299.34109138420945,\n",
       " 299.1191551724471,\n",
       " 299.09039472666296,\n",
       " 299.0943268570741,\n",
       " 299.127500680163,\n",
       " 299.06448231979925,\n",
       " 299.2073763898986,\n",
       " 298.99070509332336,\n",
       " 298.9630660124067,\n",
       " 298.96645957227054,\n",
       " 298.9996176477785,\n",
       " 298.9381634262051,\n",
       " 299.0777112988523,\n",
       " 298.866133032315,\n",
       " 298.839562995851,\n",
       " 298.8424333725967,\n",
       " 298.8755577866459,\n",
       " 298.81561580470384,\n",
       " 298.95191604863356,\n",
       " 298.7452658654086,\n",
       " 298.71971547204095,\n",
       " 298.72207798213697,\n",
       " 298.7551521674288,\n",
       " 298.69667269162505,\n",
       " 298.829820603557,\n",
       " 298.62794016932463,\n",
       " 298.60336274849044,\n",
       " 298.6052325986015,\n",
       " 298.63824124362367,\n",
       " 298.5811765959563,\n",
       " 298.7112643108125,\n",
       " 298.5140015948097,\n",
       " 298.4903530320522,\n",
       " 298.4917452851156,\n",
       " 298.5246742496072,\n",
       " 298.46897870406764,\n",
       " 298.59609530210463,\n",
       " 298.4033042844429,\n",
       " 298.38054285923204,\n",
       " 298.3814724049821,\n",
       " 298.414308641213,\n",
       " 298.35993832649626,\n",
       " 298.4841699373554,\n",
       " 298.29571033158527,\n",
       " 298.27379656668575,\n",
       " 298.27427809619064,\n",
       " 298.3070095756298,\n",
       " 298.2539223836239,\n",
       " 298.3753522873181,\n",
       " 298.191089277373,\n",
       " 298.1699857988463,\n",
       " 298.17003378267026,\n",
       " 298.20264942767,\n",
       " 298.1508049273125,\n",
       " 298.2695136521818,\n",
       " 298.08931764288053,\n",
       " 298.06898904991726,\n",
       " 298.068617719545,\n",
       " 298.10110733966894,\n",
       " 298.0504666958204,\n",
       " 298.16653211348176,\n",
       " 297.99027849382725,\n",
       " 297.970691237643,\n",
       " 297.96991456984273,\n",
       " 298.0022688025184,\n",
       " 297.95279469950304,\n",
       " 298.0662921168411,\n",
       " 297.8938610353988,\n",
       " 297.87498330650527,\n",
       " 297.8738150103338,\n",
       " 297.9060252655164,\n",
       " 297.8576818350158,\n",
       " 297.9686840832545,\n",
       " 297.7999602349282,\n",
       " 297.78176185815096,\n",
       " 297.78021536432203,\n",
       " 297.8122737728909,\n",
       " 297.76502652591097,\n",
       " 297.87360404681704,\n",
       " 297.7084764703947,\n",
       " 297.6909288070478,\n",
       " 297.6890172594201,\n",
       " 297.7209166250428,\n",
       " 297.6747323876732,\n",
       " 297.7809533169498,\n",
       " 297.6193152028204,\n",
       " 297.60239105949734,\n",
       " 297.6001273084642,\n",
       " 297.63186106268427,\n",
       " 297.58670791541385,\n",
       " 297.6906381633358,\n",
       " 297.5323866708152,\n",
       " 297.51606021431223,\n",
       " 297.51345681187775,\n",
       " 297.5450189722015,\n",
       " 297.5008661925566,\n",
       " 297.60256952191054,\n",
       " 297.44760560564976,\n",
       " 297.4318522835605,\n",
       " 297.4289214799252,\n",
       " 297.4603066106986,\n",
       " 297.4171246189936,\n",
       " 297.51666272038295,\n",
       " 297.3648909653621,\n",
       " 297.3496874319309,\n",
       " 297.346441173412,\n",
       " 297.3776443492959,\n",
       " 297.33540465729243,\n",
       " 297.43283722187726,\n",
       " 297.2841656865215,\n",
       " 297.2694897333668,\n",
       " 297.2659396615058,\n",
       " 297.2969564333652,\n",
       " 297.25563159566946,\n",
       " 297.35101638539874,\n",
       " 297.2053564523721,\n",
       " 297.19118694372656,\n",
       " 297.18734439544465,\n",
       " 297.2181707584893,\n",
       " 297.17773432650574,\n",
       " 297.2711272419174,\n",
       " 297.1283934761808,\n",
       " 297.11471028832693,\n",
       " 297.11058629699886,\n",
       " 297.14121866102147,\n",
       " 297.10164513931505,\n",
       " 297.1931002849609,\n",
       " 297.05321029870987,\n",
       " 297.039994263302,\n",
       " 297.035599560641,\n",
       " 297.06603472220473,\n",
       " 297.02729952712036,\n",
       " 297.11686927469475,\n",
       " 296.97974359880317,\n",
       " 296.9669764498055,\n",
       " 296.9623214684552,\n",
       " 296.99255658490216,\n",
       " 296.95463600530536,\n",
       " 297.0423710545369,\n",
       " 296.90793301616173,\n",
       " 296.895597340144,\n",
       " 296.8906922168807,\n",
       " 296.9207247820362,\n",
       " 296.8835959420521,\n",
       " 296.96954537942406,\n",
       " 296.8377209854528,\n",
       " 296.8258001750064,\n",
       " 296.8206547544744,\n",
       " 296.8504825759332,\n",
       " 296.8141233995577,\n",
       " 296.89833475493793,\n",
       " 296.7690525809558,\n",
       " 296.75753079101446,\n",
       " 296.7521546299188,\n",
       " 296.78177580780175,\n",
       " 296.74616498528377,\n",
       " 296.82868428651045,\n",
       " 296.7018753710157,\n",
       " 296.6907374778776,\n",
       " 296.68513984955945,\n",
       " 296.7145527566495,\n",
       " 296.67966971253935,\n",
       " 296.7605415380434,\n",
       " 296.6361392816207,\n",
       " 296.62537084448445,\n",
       " 296.61956074382914,\n",
       " 296.6487640069891,\n",
       " 296.614588869754,\n",
       " 296.6938563992732,\n",
       " 296.571796468478,\n",
       " 296.5613836933256,\n",
       " 296.55536984194094,\n",
       " 296.58436232472883,\n",
       " 296.5508758978434,\n",
       " 296.6285809612996,\n",
       " 296.5088011970071,\n",
       " 296.49873090266817,\n",
       " 296.49252175428546,\n",
       " 296.5213025406892,\n",
       " 296.4884862751309,\n",
       " 296.56466939972205,\n",
       " 296.4471097297064,\n",
       " 296.4373693159591,\n",
       " 296.43097306201867,\n",
       " 296.4595414412314,\n",
       " 296.42737740928516,\n",
       " 296.50207786486493,\n",
       " 296.38668022039735,\n",
       " 296.3772576379701,\n",
       " 296.37068221334334,\n",
       " 296.39903766552015,\n",
       " 296.36750853583146,\n",
       " 296.4407643786243,\n",
       " 296.32747261488413,\n",
       " 296.3183563372309,\n",
       " 296.3116094260529,\n",
       " 296.33975160897023,\n",
       " 296.30884062277505,\n",
       " 296.3806887374914,\n",
       " 296.26944855759405,\n",
       " 296.2606275543243,\n",
       " 296.25371659589774,\n",
       " 296.2816453324739,\n",
       " 296.2513362809354,\n",
       " 296.32181242134413,\n",
       " 296.2125713038029,\n",
       " 296.20403501565926,\n",
       " 296.19696721041345,\n",
       " 296.22468247701295,\n",
       " 296.19495967961706,\n",
       " 296.26409850762326,\n",
       " 296.1568056370791,\n",
       " 296.14854395236205,\n",
       " 296.14132626782623,\n",
       " 296.16882818332016,\n",
       " 296.13967646725865,\n",
       " 296.2075115905499,\n",
       " 296.1021177915931,\n",
       " 296.0941210239383,\n",
       " 296.0867602007236,\n",
       " 296.11404901624064,\n",
       " 296.08545369673914,\n",
       " 296.1520177050463,\n",
       " 296.04847537898706,\n",
       " 296.0407342464054,\n",
       " 296.03323680417026,\n",
       " 296.0603128934933,\n",
       " 296.03225975503545,\n",
       " 296.097584255053,\n",
       " 295.9958473194937,\n",
       " 295.98835292459887,\n",
       " 295.9807251679772,\n",
       " 296.0075890185599,\n",
       " 295.9800642969493,\n",
       " 296.0441799459792,\n",
       " 295.9442037770413,\n",
       " 295.93694758838444,\n",
       " 295.9291956128701,\n",
       " 295.95584781741115,\n",
       " 295.92883818264266,\n",
       " 295.9917747209972,\n",
       " 295.89351609807727,\n",
       " 295.886489932526,\n",
       " 295.8786196302915,\n",
       " 295.9050608788522,\n",
       " 295.8785534187383,\n",
       " 295.94033970094875,\n",
       " 295.8437567538864,\n",
       " 295.8369527599702,\n",
       " 295.82896982562187,\n",
       " 295.8552008982367,\n",
       " 295.8291831027574,\n",
       " 295.8898471276345,\n",
       " 295.79489928616727,\n",
       " 295.7883099283435,\n",
       " 295.7802198645885,\n",
       " 295.80624162434617,\n",
       " 295.7807013706809,\n",
       " 295.84027031027716,\n",
       " 295.74691825566964,\n",
       " 295.7405362994438,\n",
       " 295.7323444226719,\n",
       " 295.7581578092323,\n",
       " 295.73308334744826,\n",
       " 295.79158357494754,\n",
       " 295.69978919369754,\n",
       " 295.6936076915475,\n",
       " 295.6853191373196,\n",
       " 295.71092516084076,\n",
       " 295.68630510019176,\n",
       " 295.74376221678295,\n",
       " 295.6534885563001,\n",
       " 295.6475008343602,\n",
       " 295.63912056278957,\n",
       " 295.66452029824165,\n",
       " 295.6403435940582,\n",
       " 295.6967824548212,\n",
       " 295.60799368098327,\n",
       " 295.60219332643294,\n",
       " 295.5937261274681,\n",
       " 295.6189207093046,\n",
       " 295.5951766504411,\n",
       " 295.65062138928414,\n",
       " 295.5632827457863,\n",
       " 295.5576635949108,\n",
       " 295.549114093502,\n",
       " 295.5741047106699,\n",
       " 295.5507829074808,\n",
       " 295.6052569611681,\n",
       " 295.5193347305763,\n",
       " 295.5138908574535,\n",
       " 295.50526351861134,\n",
       " 295.53005140987653,\n",
       " 295.5071417827031,\n",
       " 295.5606679140044,\n",
       " 295.47612938043136,\n",
       " 295.4708550862064,\n",
       " 295.4621542199477,\n",
       " 295.4867406695178,\n",
       " 295.4642334376467,\n",
       " 295.51683375764554,\n",
       " 295.43364717098046,\n",
       " 295.4285369737004,\n",
       " 295.41976673987,\n",
       " 295.444153073294,\n",
       " 295.4220387443839,\n",
       " 295.4737347339698,\n",
       " 295.39186927558103,\n",
       " 295.38691790055,\n",
       " 295.3780823135333,\n",
       " 295.4022698938652,\n",
       " 295.38053925379893,\n",
       " 295.43135178438365,\n",
       " 295.3507775342326,\n",
       " 295.3459799048588,\n",
       " 295.33708283817276,\n",
       " 295.36107306237705,\n",
       " 295.3397171655365,\n",
       " 295.3896665190182,\n",
       " 295.3103544241131,\n",
       " 295.30570565322375,\n",
       " 295.2967508439893,\n",
       " 295.3205451395769,\n",
       " 295.2995552995107,\n",
       " 295.3486611875151,\n",
       " 295.27058303164847,\n",
       " 295.26607841324017,\n",
       " 295.25706946654043,\n",
       " 295.28066928841974,\n",
       " 295.26003706888673,\n",
       " 295.30831865131466,\n",
       " 295.2314470260256,\n",
       " 295.22708202742615,\n",
       " 295.21802242054326,\n",
       " 295.2414292480739,\n",
       " 295.221146454452,\n",
       " 295.2686223573587,\n",
       " 295.1929306340586,\n",
       " 295.18870088848206,\n",
       " 295.1795939750216,\n",
       " 295.20280930925776,\n",
       " 295.182867980289,\n",
       " 295.229556313121,\n",
       " 295.15501861633663,\n",
       " 295.15091991580306,\n",
       " 295.1417689297007,\n",
       " 295.1647942908128,\n",
       " 295.145186690682,\n",
       " 295.19110506289724,\n",
       " 295.1176962445763,\n",
       " 295.11372453317983,\n",
       " 295.1045325925974,\n",
       " 295.1273695174599,\n",
       " 295.1080881281813,\n",
       " 295.1532536652737,\n",
       " 295.08094928010985,\n",
       " 295.07710064761426,\n",
       " 295.06787075872023,\n",
       " 295.0905207986576,\n",
       " 295.0715583127641,\n",
       " 295.11598767171716,\n",
       " 295.0447639534425,\n",
       " 295.04103462918783,\n",
       " 295.0317696898299,\n",
       " 295.0542344085108,\n",
       " 295.03558372202485,\n",
       " 295.07929310621586,\n",
       " 295.0091269448245,\n",
       " 295.00551329192393,\n",
       " 294.9962160951944,\n",
       " 295.0184970666613,\n",
       " 295.00015127234167,\n",
       " 295.0431564459166,\n",
       " 294.9740253657731,\n",
       " 294.97052387559063,\n",
       " 294.96119711328083,\n",
       " 294.98329592011333,\n",
       " 294.96524830095916,\n",
       " 295.0075646026989,\n",
       " 294.93944674149793,\n",
       " 294.9360540283836,\n",
       " 294.92670029434083,\n",
       " 294.9486185259372,\n",
       " 294.93086254894445,\n",
       " 294.97250490564244,\n",
       " 294.90537899417524,\n",
       " 294.90209179045354,\n",
       " 294.8927135838287,\n",
       " 294.9144528348054,\n",
       " 294.8969821449576,\n",
       " 294.93796508432695,\n",
       " 294.8718104270265,\n",
       " 294.868625578215,\n",
       " 294.8592253066148,\n",
       " 294.880787175313,\n",
       " 294.8635955898018,\n",
       " 294.9039332529284,\n",
       " 294.8387297091569,\n",
       " 294.8356441694096,\n",
       " 294.82622415195056,\n",
       " 294.84761023904287,\n",
       " 294.8306917417063,\n",
       " 294.8703978950666,\n",
       " 294.8061258611105,\n",
       " 294.8031366888716,\n",
       " ...]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.f_history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1b6bcdd8>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1,len(my_model.f_history_)+1)], my_model.f_history_, marker='+', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement only one acceleration method and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolving_lr(init, final, max_itr, itr):\n",
    "    \"\"\"\n",
    "    Returns the learning rate to use at the iteration itr.\n",
    "    \n",
    "    The idea is to use a learning rate decreasing according to an inverse sigmoid function.\n",
    "    \n",
    "    Params:\n",
    "        init : initial value of the learning rate\n",
    "        final : final value of the learning rate\n",
    "        max_itr : the number of iterations used in the process\n",
    "        itr : the iteration number at which we are\n",
    "    \"\"\"\n",
    "    alpha = 2 * (np.log((init-final)/final) - np.log(np.sqrt(init/final)-1)) / max_itr\n",
    "    beta = np.log((init + final - 2*np.sqrt(init*final))/(init - final))\n",
    "    return init / (1 + np.exp(alpha*itr+beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init = 1e-2\n",
    "final = 1e-4\n",
    "max_itr = 500\n",
    "lr = []\n",
    "for itr in range(max_itr):\n",
    "    lr.append(evolving_lr(init, final, max_itr, itr))\n",
    "    \n",
    "plt.plot([itr for itr in range(max_itr)],lr)\n",
    "plt.yscale('log')\n",
    "plt.title('Evolving learning rate')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Learning rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
